{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd76e908",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from requests_html import HTMLSession, AsyncHTMLSession\n",
    "from bs4 import BeautifulSoup as bs\n",
    "\n",
    "import asyncio\n",
    "if asyncio.get_event_loop().is_running(): # Only patch if needed (i.e. running in Notebook, Spyder, etc)\n",
    "    import nest_asyncio\n",
    "    nest_asyncio.apply()\n",
    "    \n",
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5c6b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "session = AsyncHTMLSession()\n",
    "headers={'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/16.1 Safari/605.1.15'}\n",
    "\n",
    "page_rows = []\n",
    "page_num = 1\n",
    "res = 0\n",
    "total = 1\n",
    "headers_found = False\n",
    "\n",
    "while res != total:\n",
    "    \n",
    "    # get url, increment page number for next scrape\n",
    "    url = f'http://senvol.com/5_material-results/?appSession=0LTD9N6NY50DFEC28SO9N86TP49WFI6R6GEO4242743X1UP61EW017ASO6LS75SQX9CX2NW0G6Z6G8S456523E2RT203784AYQ578JEI6N0Q1I1MF957ZES52XGY3K38&PageID=2&PrevPageID=&cpipage={page_num}&CPISortType=&CPIorderBy=&appSession=26D32R65NSJT4F758HXOR2LE407P1479FX808Z5288IX77J2J5XK0RJX1Q99KFV05V5FF5K5Z1PHFF754130M6P3SQZ7CU1KUE5J5O367I9OG0YOL8WD1HH6D2D3F802&PageID=2&PrevPageID=&cpipage=2&CPISortType=&CPIorderBy='\n",
    "    page_num += 1\n",
    "    \n",
    "    # pull html data, run through beautiful soup\n",
    "    r = await session.get(url,headers=headers)\n",
    "    await r.html.arender(timeout=20, retries=3)\n",
    "    resp = r.html.raw_html\n",
    "    soup = bs(resp, 'html.parser')\n",
    "    \n",
    "    # extract table, add rows to page_rows\n",
    "    table = soup.find('table', {'id':re.compile(r'cbTable_')})\n",
    "    rows = table.find_all('tr', {'id':re.compile(r'DataRow')})\n",
    "    for row in rows:\n",
    "        page_rows.append([item.text for item in row.find_all('td')])\n",
    "    \n",
    "    # get header info\n",
    "    if not headers_found:\n",
    "        header_raw = table.find('tr', class_=re.compile(r'cbResultSetTableHeader_'))\n",
    "        header = [label.text for label in header_raw.find_all('th', class_=re.compile(r'cbResultSetHeaderCell'))]\n",
    "        headers_found = True\n",
    "    \n",
    "    # check if we should stop searching pages\n",
    "    record_text = soup.find('td', class_=re.compile(r'cbResultSetRecordMessage_')).text\n",
    "    nums = re.findall(r'\\d+', record_text)\n",
    "    res = nums[1]\n",
    "    total = nums[2]\n",
    "    \n",
    "    print(f'page {page_num-1}: results {res} of {total} scraped')\n",
    "    \n",
    "senvol_df = pd.DataFrame(page_rows, columns=header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c9b737",
   "metadata": {},
   "outputs": [],
   "source": [
    "senvol_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5640eb3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#dir_name = os.path.dirname(__File__)\n",
    "\n",
    "senvol_df.to_csv('./senvol_data1.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
